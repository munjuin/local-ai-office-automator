// backend/src/services/embedding.service.ts
import { RecursiveCharacterTextSplitter } from '@langchain/textsplitters';
import ollama from 'ollama';

export class EmbeddingService {
  // í…ìŠ¤íŠ¸ ë¶„í•  ë¡œì§ (Issue #14ì—ì„œ ì™„ì„±í•œ ë‚´ìš©)
  static async splitText(text: string, sourceName: string) {
    const splitter = new RecursiveCharacterTextSplitter({
      chunkSize: 600,
      chunkOverlap: 100,
      separators: ["\nì œ", "\nì œ\\d+ì¡°", "\n", " ", ""],
    });

    const chunks = await splitter.splitText(text);

    return chunks.map((chunk, index) => ({
      content: chunk.trim(),
      metadata: {
        source: sourceName,
        chunkIndex: index,
        parsedAt: new Date().toISOString(),
      }
    }));
  }

  // ğŸŒŸ Ollama ì„ë² ë”© ìƒì„± ë¡œì§
  static async getEmbedding(text: string): Promise<number[]> {
    try {
      const response = await ollama.embeddings({
        model: 'mxbai-embed-large',
        prompt: text,
      });
      return response.embedding;
    } catch (error) {
      console.error('Ollama Embedding Error:', error);
      throw new Error('AI ëª¨ë¸ì„ í†µí•œ ë²¡í„°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. Ollama ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.');
    }
  }
}