//uploadservice.ts
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';
import { Repository } from 'typeorm';
import * as fs from 'fs/promises';
import { PdfDocument } from './pdf-document.entity';
import { OllamaEmbeddings, ChatOllama } from '@langchain/ollama'; // ChatOllama ì¶”ê°€
import { PromptTemplate } from '@langchain/core/prompts'; // í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì¶”ê°€
import { StringOutputParser } from '@langchain/core/output_parsers'; // ì¶œë ¥ íŒŒì„œ ì¶”ê°€

interface PDFPageItem {
  str: string;
}

interface SearchResult {
  id: number;
  filename: string;
  originalName: string;
  content: string;
  similarity: number;
}

@Injectable()
export class UploadService {
  private embeddings: OllamaEmbeddings;
  private chatModel: ChatOllama; // âœ… ì±„íŒ… ëª¨ë¸ ì„ ì–¸

  constructor(
    @InjectRepository(PdfDocument)
    private pdfRepository: Repository<PdfDocument>,
  ) {
    // 1. ì„ë² ë”© ëª¨ë¸ (ê²€ìƒ‰ìš©)
    this.embeddings = new OllamaEmbeddings({
      model: 'nomic-embed-text',
      baseUrl: 'http://localhost:11434',
      ...({ numCtx: 8192 } as any),
    });

    // 2. ì±„íŒ… ëª¨ë¸ (ìƒì„±ìš© - Llama 3) âœ…
    this.chatModel = new ChatOllama({
      model: 'llama3', // âš ï¸ ì„¤ì¹˜ëœ ëª¨ë¸ëª…ì´ ë‹¤ë¥´ë‹¤ë©´ ìˆ˜ì • í•„ìš” (ì˜ˆ: 'llama3:8b')
      baseUrl: 'http://localhost:11434',
      temperature: 0.3, // 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì‚¬ì‹¤ì— ì…ê°í•œ ë‹µë³€ì„ í•©ë‹ˆë‹¤.
    });
  }

  async parsePdf(filePath: string): Promise<string> {
    const pdfjsLib = await import('pdfjs-dist/legacy/build/pdf.mjs');
    const dataBuffer = await fs.readFile(filePath);
    const uint8Array = new Uint8Array(dataBuffer);

    const loadingTask = pdfjsLib.getDocument({
      data: uint8Array,
      useSystemFonts: true,
      disableFontFace: true,
      standardFontDataUrl: 'node_modules/pdfjs-dist/standard_fonts/',
    });

    const doc = await loadingTask.promise;
    const maxPages = doc.numPages;
    const textContents: string[] = [];

    for (let i = 1; i <= maxPages; i++) {
      const page = await doc.getPage(i);
      const content = await page.getTextContent();
      const text = content.items
        .map((item: unknown) => (item as PDFPageItem).str)
        .join(' ');
      textContents.push(text);
    }

    return textContents.join('\n');
  }

  async getEmbedding(text: string): Promise<number[]> {
    const safeText = text.substring(0, 1000);
    // console.log(`ğŸ” ì„ë² ë”© ì‹œë„ í…ìŠ¤íŠ¸ ê¸¸ì´: ${safeText.length}ì`);

    if (!safeText.trim()) {
      return new Array(768).fill(0) as number[];
    }

    const vector = await this.embeddings.embedQuery(safeText);
    return vector;
  }

  async saveFile(
    filename: string,
    originalName: string,
    content: string,
  ): Promise<PdfDocument> {
    console.log('ğŸ¤– Ollamaì—ê²Œ ì„ë² ë”© ìƒì„±ì„ ìš”ì²­ ì¤‘...');
    const embedding = await this.getEmbedding(content);
    console.log(`âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ! (ì°¨ì›ìˆ˜: ${embedding.length})`);

    const newDocument = this.pdfRepository.create({
      filename,
      originalName,
      content,
      embedding,
    });

    return await this.pdfRepository.save(newDocument);
  }

  async search(question: string): Promise<SearchResult[]> {
    console.log(`ğŸ” ê²€ìƒ‰ ìš”ì²­: "${question}"`);
    const queryVector = await this.getEmbedding(question);

    const results: SearchResult[] = await this.pdfRepository.query(
      `
      SELECT 
        id, 
        filename, 
        "originalName", 
        content, 
        1 - (embedding <=> $1) as similarity
      FROM pdf_document
      ORDER BY embedding <=> $1 ASC
      LIMIT 3
      `,
      [`[${queryVector.join(',')}]`],
    );

    console.log(`âœ… ê²€ìƒ‰ ì™„ë£Œ: ${results.length}ê°œì˜ ê´€ë ¨ ë¬¸ì„œ ë°œê²¬`);
    return results;
  }

  // âœ… 3. RAG ì±„íŒ… ë©”ì„œë“œ êµ¬í˜„
  async chat(question: string): Promise<string> {
    console.log(`ğŸ’¬ ì§ˆë¬¸ ì ‘ìˆ˜: "${question}"`);

    // (1) ë¬¸ì„œ ê²€ìƒ‰ (Retrieval)
    const relevantDocs = await this.search(question);

    if (relevantDocs.length === 0) {
      return 'ì£„ì†¡í•©ë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
    }

    // (2) ë¬¸ë§¥ êµ¬ì„± (Context Augmentation)
    // ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹©ë‹ˆë‹¤.
    const context = relevantDocs.map((doc) => doc.content).join('\n\n---\n\n');

    // (3) í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‘ì„± (Prompt Engineering)
    const prompt = PromptTemplate.fromTemplate(`
      ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ AI ë¹„ì„œì…ë‹ˆë‹¤.
      ë°˜ë“œì‹œ ì•„ë˜ ì œê³µëœ [Context]ì— ê¸°ë°˜í•˜ì—¬ [Question]ì— ëŒ€í•´ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
      ë§Œì•½ [Context]ì— ì •ë‹µì´ ì—†ë‹¤ë©´, ì§€ì–´ë‚´ì§€ ë§ê³  "ì œê³µëœ ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ì†”ì§í•˜ê²Œ ë§í•˜ì„¸ìš”.

      [Context]
      {context}

      [Question]
      {question}

      ë‹µë³€:
    `);

    // (4) ì²´ì¸ ì‹¤í–‰ (LangChain Pipeline)
    // Prompt -> LLM -> OutputParser(String)
    const chain = prompt.pipe(this.chatModel).pipe(new StringOutputParser());

    console.log('ğŸ¤– Llama 3 ë‹µë³€ ìƒì„± ì¤‘...');
    const response = await chain.invoke({
      context: context,
      question: question,
    });

    console.log('âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ!');
    return response;
  }
}
