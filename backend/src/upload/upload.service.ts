//uploadservice.ts
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';
import { Repository } from 'typeorm';
import * as fs from 'fs/promises';
import { PdfDocument } from './pdf-document.entity';
import { OllamaEmbeddings, ChatOllama } from '@langchain/ollama'; // ChatOllama ì¶”ê°€
import { PromptTemplate } from '@langchain/core/prompts'; // í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì¶”ê°€
import { StringOutputParser } from '@langchain/core/output_parsers'; // ì¶œë ¥ íŒŒì„œ ì¶”ê°€

interface PDFPageItem {
  str: string;
}

interface SearchResult {
  id: number;
  filename: string;
  originalName: string;
  content: string;
  similarity: number;
}

@Injectable()
export class UploadService {
  private embeddings: OllamaEmbeddings;
  private chatModel: ChatOllama; // âœ… ì±„íŒ… ëª¨ë¸ ì„ ì–¸

  constructor(
    @InjectRepository(PdfDocument)
    private pdfRepository: Repository<PdfDocument>,
  ) {
    // 1. ì„ë² ë”© ëª¨ë¸ (ê²€ìƒ‰ìš©)

    this.embeddings = new OllamaEmbeddings({
      model: 'nomic-embed-text',
      baseUrl: 'http://localhost:11434',
      ...({ numCtx: 1024 } as any),
    });

    // 2. ì±„íŒ… ëª¨ë¸ (ìƒì„±ìš© - Llama 3) âœ…
    this.chatModel = new ChatOllama({
      model: 'llama3', // âš ï¸ ì„¤ì¹˜ëœ ëª¨ë¸ëª…ì´ ë‹¤ë¥´ë‹¤ë©´ ìˆ˜ì • í•„ìš” (ì˜ˆ: 'llama3:8b')
      baseUrl: 'http://localhost:11434',
      temperature: 0.3,
      // 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì‚¬ì‹¤ì— ì…ê°í•œ ë‹µë³€ì„ í•©ë‹ˆë‹¤.
      ...({ numCtx: 1024, num_predict: 2048 } as any),
    });
  }

  async parsePdf(filePath: string): Promise<string> {
    const pdfjsLib = await import('pdfjs-dist/legacy/build/pdf.mjs');
    const dataBuffer = await fs.readFile(filePath);
    const uint8Array = new Uint8Array(dataBuffer);

    const loadingTask = pdfjsLib.getDocument({
      data: uint8Array,
      useSystemFonts: true,
      disableFontFace: true,
      standardFontDataUrl: 'node_modules/pdfjs-dist/standard_fonts/',
    });

    const doc = await loadingTask.promise;
    const maxPages = doc.numPages;
    const textContents: string[] = [];

    for (let i = 1; i <= maxPages; i++) {
      const page = await doc.getPage(i);
      const content = await page.getTextContent();
      const text = content.items
        .map((item: unknown) => (item as PDFPageItem).str)
        .join(' ');
      textContents.push(text);
    }

    return textContents.join('\n');
  }

  async getEmbedding(text: string): Promise<number[]> {
    const safeText = text.substring(0, 1000);
    // console.log(`ğŸ” ì„ë² ë”© ì‹œë„ í…ìŠ¤íŠ¸ ê¸¸ì´: ${safeText.length}ì`);

    if (!safeText.trim()) {
      return new Array(768).fill(0) as number[];
    }

    const vector = await this.embeddings.embedQuery(safeText);
    return vector;
  }

  async saveFile(
    filename: string,
    originalName: string,
    content: string,
  ): Promise<PdfDocument> {
    console.log('ğŸ¤– Ollamaì—ê²Œ ì„ë² ë”© ìƒì„±ì„ ìš”ì²­ ì¤‘...');
    const embedding = await this.getEmbedding(content);
    console.log(`âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ! (ì°¨ì›ìˆ˜: ${embedding.length})`);

    const newDocument = this.pdfRepository.create({
      filename,
      originalName,
      content,
      embedding,
    });

    return await this.pdfRepository.save(newDocument);
  }

  async search(question: string): Promise<SearchResult[]> {
    console.log(`ğŸ” ê²€ìƒ‰ ìš”ì²­: "${question}"`);
    const queryVector = await this.getEmbedding(question);

    const results: SearchResult[] = await this.pdfRepository.query(
      `
      SELECT 
        id, 
        filename, 
        "originalName", 
        content, 
        1 - (embedding <=> $1) as similarity
      FROM pdf_document
      ORDER BY embedding <=> $1 ASC
      LIMIT 3
      `,
      [`[${queryVector.join(',')}]`],
    );

    console.log(`âœ… ê²€ìƒ‰ ì™„ë£Œ: ${results.length}ê°œì˜ ê´€ë ¨ ë¬¸ì„œ ë°œê²¬`);
    return results;
  }

  // âœ… 3. RAG ì±„íŒ… ë©”ì„œë“œ êµ¬í˜„
  async chat(question: string): Promise<string> {
    console.log(`ğŸ’¬ ì§ˆë¬¸ ì ‘ìˆ˜: "${question}"`);

    // (1) ë¬¸ì„œ ê²€ìƒ‰ (Retrieval)
    const relevantDocs = await this.search(question);

    if (relevantDocs.length === 0) {
      return 'ì£„ì†¡í•©ë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
    }

    // (2) ë¬¸ë§¥ êµ¬ì„± (Context Augmentation)
    // ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹©ë‹ˆë‹¤.
    const context = relevantDocs.map((doc) => doc.content).join('\n\n---\n\n');

    // (3) í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‘ì„± (Prompt Engineering)
    // Llama 3ì—ê²Œ "ì˜ì–´ ì§€ì‹œë¬¸"ìœ¼ë¡œ í•œêµ­ì–´ ë‹µë³€ì„ ê°•ì œí•˜ëŠ” ê²ƒì´ ë” íš¨ê³¼ì ì…ë‹ˆë‹¤.
    const prompt = PromptTemplate.fromTemplate(`
      [Context]
      {context}

      [Question]
      {question}

      ----------------
      
      ğŸ“¢ **INSTRUCTION (ì§€ì‹œì‚¬í•­)**:
      You are a "Korean AI Translator & Assistant".
      Read the [Context] above carefully, and answer the [Question].
      
      âš ï¸ **CRITICAL RULES (ë°˜ë“œì‹œ ì§€í‚¬ ê²ƒ)**:
      1. **Output Language:** ONLY Korean (í•œêµ­ì–´).
      2. **Translation:** Even if the context is in English, you MUST translate the meaning into Korean.
      3. **No English Sentences:** Do not write full sentences in English. Only use English for specific technical terms inside parentheses (e.g., "ì„ë² ë”©(Embedding)").
      4. **Accuracy:** If the answer is not in the context, say "ë¬¸ì„œì— ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤." in Korean.

      **Answer in Korean:**
    `);

    // (4) ì²´ì¸ ì‹¤í–‰ (LangChain Pipeline)
    // Prompt -> LLM -> OutputParser(String)
    const chain = prompt.pipe(this.chatModel).pipe(new StringOutputParser());

    console.log('ğŸ¤– Llama 3 ë‹µë³€ ìƒì„± ì¤‘...');
    const response = await chain.invoke({
      context: context,
      question: question,
    });

    console.log('âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ!');
    return response;
  }
}
